{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a25fa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TITANIC DATA CLEANING REPORT\n",
      "============================================================\n",
      "Initial shape: (891, 8)\n",
      "\n",
      "NaN counts:\n",
      "Survived      0\n",
      "Pclass        0\n",
      "Sex           0\n",
      "Age         177\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Fare          0\n",
      "Embarked      2\n",
      "dtype: int64\n",
      "\n",
      "Final shape after dropna: (712, 8)\n",
      "============================================================\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
      "0         0       3    0  22.0      1      0   7.2500       0.0\n",
      "1         1       1    1  38.0      1      0  71.2833       1.0\n",
      "2         1       3    1  26.0      0      0   7.9250       0.0\n",
      "3         1       1    1  35.0      1      0  53.1000       0.0\n",
      "4         0       3    0  35.0      0      0   8.0500       0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_titanic(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"TITANIC DATA CLEANING REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Select only needed columns\n",
    "    df = df[\n",
    "        [\"Survived\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "    ]\n",
    "\n",
    "    print(\"Initial shape:\", df.shape)\n",
    "\n",
    "    # Encode Sex\n",
    "    df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "    # Encode Embarked\n",
    "    df[\"Embarked\"] = df[\"Embarked\"].map({\"S\": 0, \"C\": 1, \"Q\": 2})\n",
    "\n",
    "    print(\"\\nNaN counts:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    df = df.dropna()\n",
    "\n",
    "    print(\"\\nFinal shape after dropna:\", df.shape)\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = clean_titanic(\"Titanic-Dataset.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313a00ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7\n",
      "Samples: 712 Features: 7\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# HELPER FUNCTIONS\n",
    "# ===============================\n",
    "\n",
    "def find_mean(dataset):\n",
    "    return sum(dataset) / len(dataset)\n",
    "\n",
    "def find_standard_deviation(dataset, mean):\n",
    "    return (sum((x - mean) ** 2 for x in dataset) / len(dataset)) ** 0.5\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# COMPUTE FEATURE MEANS & STDS\n",
    "# ===============================\n",
    "\n",
    "feature_means = []\n",
    "feature_stds = []\n",
    "\n",
    "FEATURE_COLUMNS = [\n",
    "    \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"\n",
    "]\n",
    "\n",
    "for col in FEATURE_COLUMNS:\n",
    "    values = df[col].tolist()\n",
    "    mean = find_mean(values)\n",
    "    std = find_standard_deviation(values, mean)\n",
    "    if std == 0:\n",
    "        std = 1.0\n",
    "\n",
    "    feature_means.append(mean)\n",
    "    feature_stds.append(std)\n",
    "\n",
    "print(len(feature_means), len(feature_stds))  # MUST be 7 7\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# NORMALIZE\n",
    "# ===============================\n",
    "\n",
    "df_normalized = df.copy()\n",
    "\n",
    "for i, col in enumerate(FEATURE_COLUMNS):\n",
    "    df_normalized[col] = [\n",
    "        (x - feature_means[i]) / feature_stds[i]\n",
    "        for x in df[col]\n",
    "    ]\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# CREATE X AND y\n",
    "# ===============================\n",
    "\n",
    "X = df_normalized[FEATURE_COLUMNS].values.tolist()\n",
    "y = df[\"Survived\"].values.tolist()\n",
    "\n",
    "n_samples = len(X)\n",
    "n_features = len(FEATURE_COLUMNS)\n",
    "\n",
    "print(\"Samples:\", n_samples, \"Features:\", n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f8851e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Weights: [-1.0123529119715262, 1.2449341311988682, -0.6205869514855857, -0.33620898504098995, -0.05013161422590291, 0.11097357038848987, 0.05142423530932826]\n",
      "Bias: -0.5159778752663623\n",
      "0.09253860964423902\n",
      "0.9066390078481562\n",
      "0.6215825938254498\n",
      "0.9059375065916172\n",
      "0.07749369296713754\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "learning_rate = 0.1\n",
    "lambda_ = 0.001\n",
    "\n",
    "weight = [random.uniform(-0.01, 0.01) for _ in range(n_features)]\n",
    "b = 0.0\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    if z >= 0:\n",
    "        return 1 / (1 + math.exp(-z))\n",
    "    else:\n",
    "        ez = math.exp(z)\n",
    "        return ez / (1 + ez)\n",
    "\n",
    "\n",
    "def find_weighted_sum_for_row(row):\n",
    "    return sum(weight[i] * row[i] for i in range(n_features)) + b\n",
    "\n",
    "\n",
    "def train_one_epoch():\n",
    "    global b\n",
    "    preds = [sigmoid(find_weighted_sum_for_row(X[j])) for j in range(n_samples)]\n",
    "\n",
    "    for i in range(n_features):\n",
    "        grad = sum((preds[j] - y[j]) * X[j][i] for j in range(n_samples)) / n_samples\n",
    "        grad += lambda_ * weight[i]\n",
    "        weight[i] -= learning_rate * grad\n",
    "\n",
    "    b_grad = sum(preds[j] - y[j] for j in range(n_samples)) / n_samples\n",
    "    b -= learning_rate * b_grad\n",
    "\n",
    "\n",
    "def train_model(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        train_one_epoch()\n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Epoch\", epoch)\n",
    "\n",
    "\n",
    "train_model(1000)\n",
    "\n",
    "print(\"Weights:\", weight)\n",
    "print(\"Bias:\", b)\n",
    "\n",
    "# test predictions\n",
    "for i in range(5):\n",
    "    print(sigmoid(find_weighted_sum_for_row(X[i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25cca303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized sample: [0.9085997380242598, -0.7561375069124817, -0.32052560120428997, -0.5527137238424564, -0.5067873731938901, -0.5163799235734484, -0.5012257320191038]\n",
      "Weighted sum: -2.05007513496581\n",
      "Survival probability: 0.11404478952972678\n",
      "\n",
      "Normalized sample 2: [-1.4829825668676924, 1.3225107746384335, 0.024712658941866902, 0.5225107881133605, 0.664747073929648, 1.2368798463153154, 1.4174448120540244]\n",
      "Weighted sum: 2.617580615882589\n",
      "Survival probability: 0.931984503335202\n"
     ]
    }
   ],
   "source": [
    "def find_sigmoid_for_sample(sample):\n",
    "    weighted_sum = sum(weight[i] * sample[i] for i in range(len(weight))) + b\n",
    "    print(\"Weighted sum:\", weighted_sum)\n",
    "    return sigmoid(weighted_sum)\n",
    "\n",
    "def normalize_sample(sample):\n",
    "    return [\n",
    "        (sample[i] - feature_means[i]) / feature_stds[i]\n",
    "        for i in range(len(sample))\n",
    "    ]\n",
    "\n",
    "\n",
    "sample = [\n",
    "    3,      # Pclass\n",
    "    0,      # Sex (male)\n",
    "    25,     # Age\n",
    "    0,      # SibSp\n",
    "    0,      # Parch\n",
    "    7.25,   # Fare\n",
    "    0       # Embarked (S)\n",
    "]\n",
    "\n",
    "\n",
    "normalized_sample = normalize_sample(sample)\n",
    "\n",
    "print(\"Normalized sample:\", normalized_sample)\n",
    "print(\"Survival probability:\", find_sigmoid_for_sample(normalized_sample))\n",
    "\n",
    "sample2 = [\n",
    "    1,      # Pclass\n",
    "    1,      # Sex (female)\n",
    "    30,     # Age\n",
    "    1,      # SibSp\n",
    "    1,      # Parch\n",
    "    100.0,  # Fare\n",
    "    1       # Embarked (C)\n",
    "]\n",
    "\n",
    "normalized_sample2 = normalize_sample(sample2)\n",
    "\n",
    "print(\"\\nNormalized sample 2:\", normalized_sample2)\n",
    "print(\"Survival probability:\", find_sigmoid_for_sample(normalized_sample2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92021560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, y_proba=None, set_name=\"Test Set\"):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation function.\n",
    "    \n",
    "    Args:\n",
    "        y_true: True labels\n",
    "        y_pred: Predicted labels\n",
    "        y_proba: Predicted probabilities (optional)\n",
    "        set_name: Name of the dataset being evaluated\n",
    "    \"\"\"\n",
    "    # Calculate metrics\n",
    "    def accuracy(y_true, y_pred):\n",
    "        correct = sum(1 for i in range(len(y_true)) if y_true.iloc[i] == y_pred[i])\n",
    "        return correct / len(y_true)\n",
    "    \n",
    "    def precision(y_true, y_pred):\n",
    "        tp = sum(1 for i in range(len(y_true)) if y_true.iloc[i] == 1 and y_pred[i] == 1)\n",
    "        fp = sum(1 for i in range(len(y_true)) if y_true.iloc[i] == 0 and y_pred[i] == 1)\n",
    "        return tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    \n",
    "    def recall(y_true, y_pred):\n",
    "        tp = sum(1 for i in range(len(y_true)) if y_true.iloc[i] == 1 and y_pred[i] == 1)\n",
    "        fn = sum(1 for i in range(len(y_true)) if y_true.iloc[i] == 1 and y_pred[i] == 0)\n",
    "        return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    def f1_score(y_true, y_pred):\n",
    "        p = precision(y_true, y_pred)\n",
    "        r = recall(y_true, y_pred)\n",
    "        return 2 * (p * r) / (p + r) if (p + r) > 0 else 0\n",
    "    \n",
    "    def confusion_matrix(y_true, y_pred):\n",
    "        tp = sum(1 for i in range(len(y_true)) if y_true.iloc[i] == 1 and y_pred[i] == 1)\n",
    "        tn = sum(1 for i in range(len(y_true)) if y_true.iloc[i] == 0 and y_pred[i] == 0)\n",
    "        fp = sum(1 for i in range(len(y_true)) if y_true.iloc[i] == 0 and y_pred[i] == 1)\n",
    "        fn = sum(1 for i in range(len(y_true)) if y_true.iloc[i] == 1 and y_pred[i] == 0)\n",
    "        return {\"TP\": tp, \"TN\": tn, \"FP\": fp, \"FN\": fn}\n",
    "    \n",
    "    # Calculate all metrics\n",
    "    acc = accuracy(y_true, y_pred)\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"MODEL EVALUATION - {set_name.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nMetrics:\")\n",
    "    print(f\"  Accuracy:  {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall:    {rec:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"                Predicted\")\n",
    "    print(f\"                Not Potable | Potable\")\n",
    "    print(f\"  Actual Not P. | {cm['TN']:<11} | {cm['FP']}\")\n",
    "    print(f\"         Potable| {cm['FN']:<11} | {cm['TP']}\")\n",
    "    \n",
    "    print(f\"\\nDetailed Breakdown:\")\n",
    "    print(f\"  True Positives (TP):  {cm['TP']} - Correctly predicted Potable\")\n",
    "    print(f\"  True Negatives (TN):  {cm['TN']} - Correctly predicted Not Potable\")\n",
    "    print(f\"  False Positives (FP): {cm['FP']} - Incorrectly predicted Potable\")\n",
    "    print(f\"  False Negatives (FN): {cm['FN']} - Incorrectly predicted Not Potable\")\n",
    "    \n",
    "    if y_proba:\n",
    "        print(f\"\\nProbability Statistics:\")\n",
    "        print(f\"  Min probability: {min(y_proba):.4f}\")\n",
    "        print(f\"  Max probability: {max(y_proba):.4f}\")\n",
    "        print(f\"  Mean probability: {sum(y_proba)/len(y_proba):.4f}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "        \"confusion_matrix\": cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e53a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac373c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b99abe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f3a7ff6",
   "metadata": {},
   "source": [
    "# Prediksi Keselamatan Penumpang Titanic Menggunakan Logistic Regression\n",
    "\n",
    "## Anggota Kelompok\n",
    "\n",
    "* Hafizh Marfiansyah Putra - 103012300201\n",
    "* Azzahra Indah - 103012300238\n",
    "\n",
    "\n",
    "## Pendahuluan dan Paparan Data\n",
    "\n",
    "Tragedi tenggelamnya kapal **RMS Titanic** pada tahun 1912 merupakan salah satu peristiwa paling terkenal dalam sejarah pelayaran. Dari kejadian tersebut, tidak semua penumpang memiliki peluang yang sama untuk selamat. Faktor seperti kelas penumpang, jenis kelamin, usia, serta kondisi keluarga diduga memengaruhi tingkat keselamatan penumpang.\n",
    "\n",
    "Pada tugas besar ini, kami membangun sebuah **model Artificial Intelligence menggunakan algoritma Logistic Regression** untuk memprediksi apakah seorang penumpang Titanic **selamat (Survived)** atau **tidak selamat**, berdasarkan beberapa atribut penumpang yang tersedia dalam dataset.\n",
    "\n",
    "## Dataset dan Sumber Data\n",
    "\n",
    "Dataset yang digunakan adalah **Titanic Dataset**, yang berisi data penumpang kapal Titanic beserta status keselamatannya. Dataset ini banyak digunakan sebagai studi kasus dalam machine learning karena memiliki struktur data yang jelas dan relevan untuk klasifikasi biner.\n",
    "\n",
    "Variabel yang digunakan dalam penelitian ini adalah:\n",
    "\n",
    "* **Survived**: Status keselamatan penumpang (target)\n",
    "* **Pclass**: Kelas penumpang\n",
    "* **Sex**: Jenis kelamin\n",
    "* **Age**: Usia penumpang\n",
    "* **SibSp**: Jumlah saudara atau pasangan di kapal\n",
    "* **Parch**: Jumlah orang tua atau anak di kapal\n",
    "* **Fare**: Harga tiket\n",
    "* **Embarked**: Pelabuhan keberangkatan\n",
    "\n",
    "## Pre-processing Dataset\n",
    "\n",
    "Sebelum membangun model, dataset melalui beberapa tahapan pre-processing, antara lain:\n",
    "\n",
    "* Pemilihan fitur yang relevan sesuai variabel yang digunakan\n",
    "* Penanganan data kategorikal seperti **Sex** dan **Embarked**\n",
    "* Penanganan data kosong atau tidak valid\n",
    "* Penyesuaian format data agar dapat diproses oleh model Logistic Regression\n",
    "\n",
    "Tahapan ini bertujuan untuk meningkatkan kualitas data dan performa model yang dibangun.\n",
    "\n",
    "## Pembagian Data Training, Validasi, dan Testing\n",
    "\n",
    "Dataset dibagi menjadi tiga bagian untuk memastikan model dapat dilatih dan dievaluasi dengan baik:\n",
    "\n",
    "* **60% data** digunakan sebagai **training set** untuk melatih model\n",
    "* **20% data** digunakan sebagai **validation set** untuk mengevaluasi dan menyetel model\n",
    "* **20% data** digunakan sebagai **testing set** untuk mengukur performa akhir model\n",
    "\n",
    "Pembagian data dilakukan secara acak dengan menggunakan seed tertentu agar hasil eksperimen dapat direproduksi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a25fa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used (9): ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_S', 'Embarked_C', 'Embarked_Q']\n",
      "\n",
      "Dataset split:\n",
      "Training   : 534\n",
      "Validation : 178\n",
      "Testing    : 179\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# ===============================\n",
    "# 1. LOAD DATA\n",
    "# ===============================\n",
    "df = pd.read_csv('Titanic-Dataset.csv')\n",
    "\n",
    "# ===============================\n",
    "# 2. BASIC CLEANING\n",
    "# ===============================\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "df['Embarked'] = df['Embarked'].fillna('S')\n",
    "\n",
    "# ===============================\n",
    "# 3. ENCODE CATEGORICAL FEATURES\n",
    "# ===============================\n",
    "\n",
    "\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# One-hot encode Embarked\n",
    "df['Embarked_S'] = (df['Embarked'] == 'S').astype(int)\n",
    "df['Embarked_C'] = (df['Embarked'] == 'C').astype(int)\n",
    "df['Embarked_Q'] = (df['Embarked'] == 'Q').astype(int)\n",
    "\n",
    "# ===============================\n",
    "# 4. FEATURES & TARGET\n",
    "# ===============================\n",
    "feature_names = [\n",
    "    'Pclass',\n",
    "    'Sex',\n",
    "    'Age',\n",
    "    'SibSp',\n",
    "    'Parch',\n",
    "    'Fare',\n",
    "    'Embarked_S',\n",
    "    'Embarked_C',\n",
    "    'Embarked_Q'\n",
    "]\n",
    "\n",
    "X = df[feature_names].values.tolist()\n",
    "y = df['Survived'].values.tolist()\n",
    "\n",
    "n_features = len(feature_names)\n",
    "\n",
    "print(f\"Features used ({n_features}): {feature_names}\")\n",
    "\n",
    "# ===============================\n",
    "# 5. TRAIN / VAL / TEST SPLIT (60 / 20 / 20)\n",
    "# ===============================\n",
    "random.seed(69)\n",
    "\n",
    "indices = list(range(len(X)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "n_total = len(indices)\n",
    "train_end = int(0.6 * n_total)\n",
    "val_end   = int(0.8 * n_total)\n",
    "\n",
    "train_idx = indices[:train_end]\n",
    "val_idx   = indices[train_end:val_end]\n",
    "test_idx  = indices[val_end:]\n",
    "\n",
    "X_train = [X[i] for i in train_idx]\n",
    "y_train = [y[i] for i in train_idx]\n",
    "\n",
    "X_val = [X[i] for i in val_idx]\n",
    "y_val = [y[i] for i in val_idx]\n",
    "\n",
    "X_test = [X[i] for i in test_idx]\n",
    "y_test = [y[i] for i in test_idx]\n",
    "\n",
    "print(\"\\nDataset split:\")\n",
    "print(f\"Training   : {len(X_train)}\")\n",
    "print(f\"Validation : {len(X_val)}\")\n",
    "print(f\"Testing    : {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea6b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column values: [2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0]\n",
      "Column values: [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Column values: [32.0, 22.0, 60.0, 0.83, 9.0, 20.0, 19.0, 26.0, 19.0, 21.0, 4.0, 9.0, 16.0, 28.0, 22.0, 54.0, 30.0, 4.0, 48.0, 23.0, 30.0, 28.0, 23.0, 39.0, 55.5, 28.0, 20.5, 38.0, 30.0, 28.0, 25.0, 30.5, 3.0, 21.0, 28.0, 0.75, 18.0, 45.0, 56.0, 28.0, 40.0, 29.0, 40.0, 28.0, 70.0, 28.0, 28.0, 19.0, 50.0, 28.0, 28.0, 28.0, 28.0, 28.0, 39.0, 24.0, 28.0, 26.0, 26.0, 34.0, 0.67, 2.0, 33.0, 21.0, 28.0, 28.0, 36.0, 28.0, 19.0, 28.0, 59.0, 18.0, 27.0, 33.0, 24.0, 23.0, 28.0, 24.0, 29.0, 44.0, 21.0, 28.0, 50.0, 3.0, 17.0, 22.0, 28.0, 16.0, 38.0, 35.0, 70.5, 22.0, 1.0, 34.0, 38.0, 42.0, 28.0, 22.0, 20.0, 10.0, 8.0, 2.0, 27.0, 7.0, 39.0, 48.0, 28.0, 55.0, 42.0, 15.0, 28.0, 31.0, 28.0, 21.0, 22.0, 19.0, 28.0, 45.0, 47.0, 38.0, 28.0, 20.0, 13.0, 5.0, 47.0, 28.0, 2.0, 33.0, 20.0, 25.0, 28.0, 40.0, 22.0, 40.0, 28.0, 22.0, 19.0, 28.0, 19.0, 26.0, 42.0, 33.0, 31.0, 28.0, 16.0, 16.0, 39.0, 28.0, 23.0, 74.0, 51.0, 54.0, 28.0, 22.0, 41.0, 26.0, 28.0, 17.0, 41.0, 36.0, 32.0, 58.0, 18.0, 39.0, 29.0, 30.0, 36.0, 33.0, 19.0, 45.0, 49.0, 33.0, 45.0, 29.0, 30.0, 33.0, 31.0, 19.0, 80.0, 28.0, 28.0, 49.0, 39.0, 45.5, 10.0, 28.0, 54.0, 34.0, 28.0, 28.0, 28.0, 28.0, 20.0, 28.0, 34.0, 39.0, 5.0, 35.0, 49.0, 47.0, 15.0, 18.0, 35.0, 28.0, 55.0, 28.0, 61.0, 18.0, 28.0, 25.0, 32.0, 21.0, 28.0, 28.0, 22.0, 28.0, 50.0, 16.0, 37.0, 22.0, 11.0, 21.0, 4.0, 41.0, 28.0, 28.0, 70.0, 48.0, 54.0, 36.0, 52.0, 15.0, 28.0, 20.0, 51.0, 24.0, 36.0, 30.0, 28.0, 25.0, 28.0, 28.0, 28.0, 17.0, 18.0, 14.0, 19.0, 57.0, 28.0, 40.0, 40.0, 28.0, 32.0, 9.0, 28.0, 28.0, 28.0, 35.0, 57.0, 18.0, 14.0, 28.0, 30.0, 20.0, 38.0, 16.0, 28.0, 28.0, 28.0, 34.0, 39.0, 62.0, 36.0, 23.0, 4.0, 28.0, 45.0, 28.0, 25.0, 1.0, 29.0, 25.0, 19.0, 17.0, 29.0, 32.0, 11.0, 38.0, 13.0, 2.0, 38.0, 25.0, 14.0, 28.0, 24.0, 28.0, 47.0, 28.0, 37.0, 14.0, 30.0, 28.0, 30.0, 36.0, 22.0, 28.0, 36.0, 6.0, 28.0, 0.83, 30.0, 35.0, 3.0, 44.0, 28.0, 22.0, 42.0, 28.0, 24.0, 28.0, 20.0, 25.0, 19.0, 9.0, 28.0, 11.0, 41.0, 24.0, 32.0, 36.0, 62.0, 2.0, 30.0, 30.0, 28.0, 58.0, 50.0, 36.0, 29.0, 35.0, 27.0, 31.0, 18.0, 15.0, 37.0, 35.0, 54.0, 24.0, 1.0, 28.0, 28.0, 28.0, 2.0, 29.0, 30.0, 27.0, 30.0, 24.0, 18.0, 22.0, 45.0, 31.0, 47.0, 24.0, 18.0, 16.0, 30.0, 43.0, 22.0, 28.0, 19.0, 34.0, 65.0, 36.0, 25.0, 8.0, 34.0, 5.0, 24.0, 28.0, 28.0, 26.0, 16.0, 32.5, 41.0, 28.0, 26.0, 24.0, 52.0, 34.0, 44.0, 28.0, 28.0, 17.0, 18.0, 27.0, 23.0, 32.0, 32.0, 28.0, 34.0, 28.0, 39.0, 51.0, 44.0, 33.0, 40.5, 52.0, 28.0, 22.0, 28.0, 36.0, 30.0, 31.0, 24.0, 62.0, 24.0, 25.0, 26.0, 17.0, 61.0, 40.0, 28.0, 24.0, 36.0, 40.0, 44.0, 22.0, 18.0, 26.0, 27.0, 38.0, 27.0, 19.0, 48.0, 36.0, 28.0, 24.0, 33.0, 28.0, 60.0, 4.0, 28.0, 28.0, 63.0, 33.0, 19.0, 44.0, 16.0, 28.0, 43.0, 28.0, 56.0, 26.0, 7.0, 37.0, 18.0, 30.0, 58.0, 28.0, 31.0, 32.0, 16.0, 42.0, 21.0, 28.0, 22.0, 23.0, 29.0, 16.0, 16.0, 23.5, 38.0, 47.0, 28.0, 22.0, 28.0, 21.0, 18.0, 35.0, 9.0, 4.0, 51.0, 36.0, 28.0, 6.0, 20.0, 28.0, 66.0, 25.0, 60.0, 50.0, 36.0, 40.5, 2.0, 35.0, 28.0, 21.0, 21.0, 22.0, 39.0, 28.0, 23.0, 50.0, 28.0, 45.0, 23.0, 3.0, 36.0, 21.0, 40.0, 22.0, 1.0, 28.0, 27.0, 31.0, 24.0, 17.0, 25.0, 26.0, 48.0, 28.0, 21.0, 42.0, 25.0, 18.0, 30.0, 28.0, 18.0, 28.0, 18.0, 46.0, 52.0, 25.0]\n",
      "Column values: [1.0, 0.0, 1.0, 1.0, 5.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 8.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 5.0, 8.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0]\n",
      "Column values: [0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 6.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "Column values: [26.0, 7.25, 75.25, 18.75, 46.9, 7.925, 30.0, 8.6625, 10.5, 7.7333, 23.0, 15.2458, 8.05, 7.8792, 7.775, 51.8625, 13.0, 13.4167, 26.55, 7.925, 7.225, 56.4958, 113.275, 79.65, 8.05, 29.7, 7.25, 227.525, 7.25, 7.6292, 7.7417, 7.75, 41.5792, 34.375, 7.75, 19.2583, 13.0, 83.475, 26.55, 69.55, 27.9, 26.0, 13.0, 8.05, 10.5, 7.225, 26.55, 7.8792, 28.7125, 7.8958, 7.75, 7.8792, 35.5, 50.0, 55.9, 7.8958, 7.2292, 7.8542, 30.0, 13.0, 14.5, 10.4625, 26.0, 9.825, 23.45, 7.75, 7.4958, 8.6625, 53.1, 14.4583, 13.5, 14.4542, 7.8958, 7.8958, 24.15, 13.0, 23.25, 8.05, 7.775, 7.925, 77.9583, 7.225, 55.9, 21.075, 8.6625, 9.8375, 25.4667, 57.9792, 90.0, 53.1, 7.75, 151.55, 11.1333, 10.5, 80.0, 13.0, 89.1042, 29.0, 7.05, 24.15, 36.75, 151.55, 53.1, 26.25, 110.8833, 34.375, 30.5, 30.5, 227.525, 14.4542, 24.0, 57.0, 6.95, 7.7958, 7.8958, 26.0, 33.0, 27.9, 15.0, 31.3875, 7.2292, 4.0125, 7.2292, 12.475, 52.0, 25.4667, 26.0, 27.75, 7.2292, 7.925, 13.0, 15.5, 7.225, 31.0, 227.525, 8.05, 7.8958, 14.4542, 7.8542, 7.8958, 8.6625, 8.6542, 37.0042, 8.05, 34.375, 86.5, 83.1583, 0.0, 13.0, 7.775, 7.0542, 23.0, 8.1125, 9.35, 19.5, 7.925, 7.7292, 8.6625, 20.2125, 71.0, 76.2917, 146.5208, 9.8417, 7.925, 8.05, 10.5, 135.6333, 53.1, 7.775, 8.05, 110.8833, 9.5, 35.5, 26.0, 21.0, 5.0, 18.0, 26.2833, 30.0, 13.0, 0.0, 56.9292, 29.125, 28.5, 27.9, 7.8958, 59.4, 8.05, 15.5, 7.8292, 7.8292, 8.05, 8.6625, 8.05, 32.5, 26.0, 27.75, 512.3292, 25.9292, 25.5875, 211.3375, 13.0, 83.475, 133.65, 16.0, 21.6792, 32.3208, 9.35, 47.1, 7.8958, 8.05, 8.05, 24.15, 51.8625, 7.25, 7.75, 8.05, 39.6875, 26.0, 7.75, 18.7875, 7.925, 22.025, 39.6875, 7.2292, 7.8958, 71.0, 52.0, 26.0, 512.3292, 30.5, 7.225, 8.1375, 9.5, 77.9583, 16.7, 26.3875, 12.475, 7.2292, 7.25, 0.0, 7.8542, 10.5, 7.125, 7.75, 120.0, 10.1708, 10.5, 7.05, 153.4625, 9.475, 7.2292, 10.5, 27.9, 7.75, 221.7792, 7.2292, 512.3292, 12.35, 7.4958, 46.9, 7.75, 13.0, 9.8458, 71.2833, 7.7333, 7.925, 7.8958, 7.8958, 6.4958, 31.275, 80.0, 24.15, 7.55, 16.7, 26.55, 26.25, 22.3583, 151.55, 20.575, 10.5, 7.775, 6.75, 7.0542, 30.0, 7.925, 31.275, 7.05, 19.5, 27.9, 7.8958, 13.0, 7.8542, 8.05, 26.0, 7.775, 14.5, 7.225, 52.5542, 30.0708, 9.5, 0.0, 13.0, 120.0, 41.5792, 8.05, 17.4, 12.475, 110.8833, 29.0, 24.0, 7.05, 18.75, 27.7208, 15.85, 135.6333, 52.0, 25.925, 18.75, 14.5, 7.8542, 26.0, 26.0, 31.275, 7.775, 120.0, 14.1083, 13.0, 7.925, 40.125, 10.5, 31.275, 7.2292, 16.1, 7.7958, 113.275, 13.0, 13.0, 21.075, 8.05, 7.7958, 7.925, 8.3, 8.0292, 53.1, 8.05, 26.0, 13.0, 39.0, 23.25, 7.75, 7.25, 12.2875, 211.3375, 12.35, 6.975, 56.9292, 263.0, 11.5, 7.8958, 7.75, 13.0, 9.0, 10.5, 8.05, 26.0, 8.05, 8.05, 9.0, 69.55, 8.1583, 14.4, 61.9792, 7.8958, 7.05, 26.25, 21.0, 31.3875, 9.5, 15.5, 39.6, 7.775, 7.75, 13.0, 7.125, 22.3583, 18.7875, 83.1583, 13.5, 13.0, 26.0, 12.65, 16.1, 7.2292, 73.5, 10.5, 63.3583, 15.5, 56.4958, 56.4958, 8.05, 56.4958, 13.0, 8.05, 8.05, 8.6625, 7.75, 78.2667, 7.225, 55.0, 0.0, 10.5, 7.8958, 52.0, 79.2, 26.55, 69.3, 7.05, 7.8875, 108.9, 6.2375, 27.7208, 15.2458, 247.5208, 120.0, 0.0, 8.05, 7.125, 6.75, 78.85, 14.4542, 8.6625, 30.5, 14.5, 7.8542, 13.0, 25.4667, 65.0, 7.8958, 7.75, 26.55, 27.9, 0.0, 69.55, 9.5875, 7.775, 13.0, 57.9792, 10.5, 19.9667, 46.9, 26.55, 30.6958, 20.575, 39.6875, 7.925, 17.8, 93.5, 29.7, 7.75, 10.5, 15.85, 8.05, 7.65, 7.25, 8.05, 66.6, 10.5, 7.75, 9.5, 18.0, 7.2292, 153.4625, 52.5542, 52.0, 7.25, 23.45, 7.8, 79.65, 7.8958, 31.3875, 11.1333, 7.75, 12.875, 22.525, 33.0, 7.8542, 8.05, 10.5, 91.0792, 39.0, 10.5, 0.0, 14.5, 29.125, 90.0, 15.5, 8.4333, 8.05, 49.5, 13.0, 7.225, 11.5, 106.425, 7.75, 26.55, 7.8542, 15.9, 15.55, 7.775, 15.75, 8.05, 46.9, 69.55, 76.7292, 26.25, 14.5, 57.0, 7.775, 26.0, 13.0, 14.4583, 7.925, 26.2875, 26.0, 7.775, 24.15, 7.25, 262.375, 7.55, 11.5, 61.175, 79.65, 17.8]\n",
      "Column values: [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Column values: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Column values: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Means: [2.316479400749064, 0.37453183520599254, 29.28385767790262, 0.5037453183520599, 0.40636704119850187, 32.37075524344569, 0.7490636704119851, 0.17228464419475656, 0.07865168539325842]\n",
      "Stds : [0.8340988782597946, 0.4840017971280931, 13.318693183438677, 1.0630784473991204, 0.8685283433822334, 53.149568952446124, 0.43355194392472757, 0.3776276546671903, 0.2691943494541784]\n",
      "Normalization complete.\n",
      "Example original row: [-0.3794267190591892, -0.7738232325341369, 0.20393459663706393, 0.4668090890771554, -0.4678799998812042, -0.11986466436154397, 0.5787918451395111, -0.45622888595538363, -0.29217435489538873]\n",
      "Example scaled row:   [-0.3794, -0.7738, 0.2039, 0.4668, -0.4679, -0.1199, 0.5788, -0.4562, -0.2922]\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# HELPER FUNCTIONS\n",
    "# ===============================\n",
    "\n",
    "def find_mean(dataset):\n",
    "    return sum(dataset) / len(dataset)\n",
    "\n",
    "def find_standard_deviation(dataset, mean):\n",
    "    return (sum((x - mean) ** 2 for x in dataset) / len(dataset)) ** 0.5\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# COMPUTE MEANS & STDS (TRAIN ONLY)\n",
    "# ===============================\n",
    "\n",
    "feature_means = []\n",
    "feature_stds = []\n",
    "\n",
    "for feature_idx in range(n_features):\n",
    "    column_values = [row[feature_idx] for row in X_train]\n",
    "    print(\"Column values:\", column_values)\n",
    "    mean = find_mean(column_values)\n",
    "    std = find_standard_deviation(column_values, mean)\n",
    "\n",
    "    if std == 0:\n",
    "        std = 1.0\n",
    "\n",
    "    feature_means.append(mean)\n",
    "    feature_stds.append(std)\n",
    "\n",
    "print(\"Means:\", feature_means)\n",
    "print(\"Stds :\", feature_stds)\n",
    "\n",
    "# ===============================\n",
    "# 2. APPLY NORMALIZATION FUNCTION\n",
    "# ===============================\n",
    "def scale_dataset(data, means, stds):\n",
    "    scaled_data = []\n",
    "    for row in data:\n",
    "        new_row = [(row[i] - means[i]) / stds[i] for i in range(len(row))]\n",
    "        scaled_data.append(new_row)\n",
    "    return scaled_data\n",
    "\n",
    "# Normalize all splits\n",
    "X_train = scale_dataset(X_train, feature_means, feature_stds)\n",
    "X_val  = scale_dataset(X_val, feature_means, feature_stds)\n",
    "X_test  = scale_dataset(X_test, feature_means, feature_stds)\n",
    "\n",
    "print(\"Normalization complete.\")\n",
    "print(f\"Example original row: {X_train[0]}\")\n",
    "print(f\"Example scaled row:   {[round(x, 4) for x in X_train[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b025a26b",
   "metadata": {},
   "source": [
    "## Metode dan Eksperimen\n",
    "\n",
    "### Metode yang Digunakan\n",
    "\n",
    "Pada penelitian ini, metode yang digunakan adalah **Logistic Regression**, yaitu salah satu algoritma klasifikasi biner yang memodelkan hubungan antara variabel input dan probabilitas suatu kelas. Logistic Regression digunakan untuk menghitung **probabilitas seorang penumpang Titanic selamat atau tidak selamat**, dengan memanfaatkan fungsi sigmoid sebagai fungsi aktivasi.\n",
    "\n",
    "Model dibangun dari awal tanpa menggunakan library machine learning eksternal. Proses pelatihan dilakukan menggunakan **gradient descent** dengan regularisasi L2 (ridge) untuk mengurangi risiko overfitting. Parameter model yang dipelajari meliputi bobot (weight) untuk setiap fitur dan sebuah bias.\n",
    "\n",
    "Fungsi sigmoid digunakan untuk mengubah hasil perhitungan linear menjadi nilai probabilitas antara 0 dan 1. Nilai probabilitas tersebut kemudian dikonversi menjadi kelas prediksi dengan threshold 0.5.\n",
    "\n",
    "### Pengukuran Kinerja Model\n",
    "\n",
    "Kinerja model dievaluasi menggunakan **metrik akurasi (accuracy)**. Akurasi mengukur seberapa besar proporsi prediksi yang benar dibandingkan dengan keseluruhan data.\n",
    "\n",
    "Evaluasi dilakukan pada tiga subset data:\n",
    "\n",
    "* **Training set** untuk melatih model\n",
    "* **Validation set** untuk memilih hyperparameter terbaik\n",
    "* **Testing set** untuk mengukur performa akhir model\n",
    "\n",
    "Penggunaan data validasi bertujuan agar proses pemilihan hyperparameter tidak bias terhadap data uji, sehingga hasil evaluasi lebih objektif.\n",
    "\n",
    "### Hyperparameter dan Hyperparameter Tuning\n",
    "\n",
    "Beberapa hyperparameter utama yang digunakan dalam model Logistic Regression adalah:\n",
    "\n",
    "* **Learning rate**, yang mengatur besar langkah pembaruan parameter\n",
    "* **Lambda**, sebagai parameter regularisasi untuk mengontrol kompleksitas model\n",
    "* **Jumlah epoch**, yang menentukan berapa kali proses pelatihan dilakukan terhadap seluruh data training\n",
    "\n",
    "Untuk memperoleh kombinasi hyperparameter yang optimal, digunakan metode **Genetic Algorithm**. Genetic Algorithm bekerja dengan meniru proses evolusi biologis, yaitu melalui tahapan inisialisasi populasi, evaluasi fitness, seleksi, crossover, dan mutasi.\n",
    "\n",
    "Setiap individu dalam populasi merepresentasikan satu kombinasi hyperparameter. Nilai **fitness** ditentukan berdasarkan akurasi model pada data validasi. Individu dengan performa terbaik akan dipertahankan dan dikombinasikan untuk menghasilkan generasi berikutnya.\n",
    "\n",
    "Proses ini dijalankan selama beberapa generasi hingga diperoleh kombinasi hyperparameter dengan performa validasi terbaik. Hyperparameter hasil Genetic Algorithm kemudian digunakan untuk melatih model akhir sebelum dilakukan pengujian pada data testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "313a00ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n",
      "\n",
      "Trained weights: [-0.8528401580640919, 1.1428016530664011, -0.4937577853735852, -0.3230164454406365, -0.1235248331159867, 0.11377776499587265, -0.07583701729349236, 0.03945911121778763, 0.06819040238943]\n",
      "Trained bias: -0.552810349840814\n",
      "\n",
      "Test predictions (first 5):\n",
      "Sample 0: probability=0.1117, predicted=0, actual=0\n",
      "Sample 1: probability=0.5878, predicted=1, actual=0\n",
      "Sample 2: probability=0.0406, predicted=0, actual=0\n",
      "Sample 3: probability=0.0612, predicted=0, actual=0\n",
      "Sample 4: probability=0.8505, predicted=1, actual=1\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "# ===============================\n",
    "# HYPERPARAMETERS\n",
    "# ===============================\n",
    "learning_rate = 0.024104914547185125\n",
    "lambda_ = 0.008886564986697631\n",
    "epochs = 3165\n",
    "\n",
    "# ===============================\n",
    "# DATA SIZES\n",
    "# ===============================\n",
    "n_samples = len(X_train)\n",
    "n_features = len(X_train[0])\n",
    "\n",
    "# ===============================\n",
    "# INITIALIZE PARAMETERS\n",
    "# ===============================\n",
    "weight = [random.uniform(-0.01, 0.01) for _ in range(n_features)]\n",
    "b = 0.0\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# MODEL FUNCTIONS\n",
    "# ===============================\n",
    "def sigmoid(z):\n",
    "    if z >= 0:\n",
    "        return 1 / (1 + math.exp(-z))\n",
    "    else:\n",
    "        ez = math.exp(z)\n",
    "        return ez / (1 + ez)\n",
    "\n",
    "\n",
    "def find_weighted_sum_for_row(row):\n",
    "    return sum(weight[i] * row[i] for i in range(n_features)) + b\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# TRAINING\n",
    "# ===============================\n",
    "def train_logistic_regression(X_train, y_train, lr, lambda_, epochs):\n",
    "    n_samples = len(X_train)\n",
    "    n_features = len(X_train[0])\n",
    "\n",
    "    # initialize parameters\n",
    "    weight = [random.uniform(-0.01, 0.01) for _ in range(n_features)]\n",
    "    b = 0.0\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        preds = [\n",
    "            sigmoid(sum(weight[i] * X_train[j][i] for i in range(n_features)) + b)\n",
    "            for j in range(n_samples)\n",
    "        ]\n",
    "\n",
    "        # update weights\n",
    "        for i in range(n_features):\n",
    "            grad = sum((preds[j] - y_train[j]) * X_train[j][i] for j in range(n_samples)) / n_samples\n",
    "            grad += lambda_ * weight[i]\n",
    "            weight[i] -= lr * grad\n",
    "\n",
    "        # update bias\n",
    "        b_grad = sum(preds[j] - y_train[j] for j in range(n_samples)) / n_samples\n",
    "        b -= lr * b_grad\n",
    "\n",
    "    return weight, b\n",
    "\n",
    "\n",
    "def train_model(epochs):\n",
    "    global weight, b\n",
    "    weight, b = train_logistic_regression(X_train, y_train, learning_rate, lambda_, epochs)\n",
    "    print(f\"Training completed.\")\n",
    "\n",
    "def accuracy(X, y, weight, b):\n",
    "    correct = 0\n",
    "    for i in range(len(X)):\n",
    "        z = sum(weight[j] * X[i][j] for j in range(len(weight))) + b\n",
    "        pred = 1 if sigmoid(z) >= 0.5 else 0\n",
    "        if pred == y[i]:\n",
    "            correct += 1\n",
    "    return correct / len(X)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# TRAIN\n",
    "# ===============================\n",
    "train_model(epochs)\n",
    "\n",
    "print(\"\\nTrained weights:\", weight)\n",
    "print(\"Trained bias:\", b)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# TEST ON TEST SET\n",
    "# ===============================\n",
    "print(\"\\nTest predictions (first 5):\")\n",
    "for i in range(5):\n",
    "    p = sigmoid(find_weighted_sum_for_row(X_test[i]))\n",
    "    print(f\"Sample {i}: probability={p:.4f}, predicted={1 if p>=0.5 else 0}, actual={y_test[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7c12c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 0\n",
      "  {'lr': 0.04810539848261843, 'lambda': 0.003286222431548926, 'epochs': 3309} → val acc = 0.7921\n",
      "  {'lr': 0.032232380240248604, 'lambda': 0.0061882078006781265, 'epochs': 14614} → val acc = 0.7921\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.007422706132235075, 'epochs': 7295} → val acc = 0.7921\n",
      "  {'lr': 0.010303356655745655, 'lambda': 0.007414217377458676, 'epochs': 5124} → val acc = 0.7921\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.04140076715116696, 'lambda': 0.007985619433582818, 'epochs': 6526} → val acc = 0.7921\n",
      "  {'lr': 0.015319565964190724, 'lambda': 0.001321524003805649, 'epochs': 11979} → val acc = 0.7921\n",
      "  {'lr': 0.04232140743824378, 'lambda': 0.00782935910497672, 'epochs': 8028} → val acc = 0.7921\n",
      "\n",
      "Generation 1\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.04810539848261843, 'lambda': 0.003286222431548926, 'epochs': 3309} → val acc = 0.7921\n",
      "  {'lr': 0.032232380240248604, 'lambda': 0.0061882078006781265, 'epochs': 14614} → val acc = 0.7921\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.007422706132235075, 'epochs': 7295} → val acc = 0.7921\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.008052620900173522, 'epochs': 7295} → val acc = 0.7921\n",
      "  {'lr': 0.032232380240248604, 'lambda': 0.0061882078006781265, 'epochs': 14614} → val acc = 0.7921\n",
      "\n",
      "Generation 2\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.04810539848261843, 'lambda': 0.003286222431548926, 'epochs': 3309} → val acc = 0.7921\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 11415} → val acc = 0.7921\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003286222431548926, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.05018670296636611, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7921\n",
      "\n",
      "Generation 3\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.003117436294968344, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "\n",
      "Generation 4\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 11415} → val acc = 0.7921\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "\n",
      "Generation 5\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0024461191430083526, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0026356218209899903, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.0031978636869540965, 'epochs': 3309} → val acc = 0.7978\n",
      "\n",
      "Generation 6\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.0019049462977235242, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.8034\n",
      "  {'lr': 0.002454210401299306, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "\n",
      "Generation 7\n",
      "  {'lr': 0.0019049462977235242, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.8034\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.001703205858760887, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7921\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.0029271952186403108, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.002999062628301703, 'epochs': 3309} → val acc = 0.7978\n",
      "\n",
      "Generation 8\n",
      "  {'lr': 0.0019049462977235242, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.8034\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.01094920198822552, 'lambda': 0.003268588048818244, 'epochs': 3309} → val acc = 0.7921\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0034577645608472093, 'epochs': 11415} → val acc = 0.7921\n",
      "  {'lr': 0.011825219561734407, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7921\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "\n",
      "Generation 9\n",
      "  {'lr': 0.0019049462977235242, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.8034\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.0029271952186403108, 'epochs': 3309} → val acc = 0.7978\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7921\n",
      "  {'lr': 0.010137759234555732, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7921\n",
      "  {'lr': 0.00899871638605753, 'lambda': 0.003233877101535049, 'epochs': 3309} → val acc = 0.8034\n",
      "  {'lr': 0.0020532744885462043, 'lambda': 0.003233877101535049, 'epochs': 11415} → val acc = 0.7978\n",
      "\n",
      "BEST HYPERPARAMETERS FOUND:\n",
      "{'lr': 0.0019049462977235242, 'lambda': 0.003233877101535049, 'epochs': 11415}\n",
      "Validation accuracy: 0.8033707865168539\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# GENETIC ALGORITHM\n",
    "# ===============================\n",
    "\n",
    "POP_SIZE = 8\n",
    "GENERATIONS = 10\n",
    "MUTATION_RATE = 0.2\n",
    "\n",
    "\n",
    "def random_individual():\n",
    "    return {\n",
    "        \"lr\": random.uniform(0.001, 0.05),\n",
    "        \"lambda\": random.uniform(0.00001, 0.01),\n",
    "        \"epochs\": random.randint(3000, 15000)\n",
    "    }\n",
    "\n",
    "\n",
    "def fitness(individual):\n",
    "    weight, b = train_logistic_regression(X_train, y_train,individual[\"lr\"],individual[\"lambda\"],individual[\"epochs\"]\n",
    "    )\n",
    "    return accuracy(X_val, y_val, weight, b)\n",
    "\n",
    "\n",
    "# initialize population\n",
    "population = [random_individual() for _ in range(POP_SIZE)]\n",
    "\n",
    "best_individual = None\n",
    "best_score = 0\n",
    "\n",
    "for gen in range(GENERATIONS):\n",
    "    print(f\"\\nGeneration {gen}\")\n",
    "\n",
    "    scored = []\n",
    "    for ind in population:\n",
    "        score = fitness(ind)\n",
    "        scored.append((score, ind))\n",
    "        print(f\"  {ind} → val acc = {score:.4f}\")\n",
    "\n",
    "    scored.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "    if scored[0][0] > best_score:\n",
    "        best_score = scored[0][0]\n",
    "        best_individual = scored[0][1]\n",
    "\n",
    "    # selection (top 50%)\n",
    "    survivors = [ind for _, ind in scored[:POP_SIZE // 2]]\n",
    "\n",
    "    # crossover + mutation\n",
    "    new_population = survivors.copy()\n",
    "\n",
    "    while len(new_population) < POP_SIZE:\n",
    "        parent1 = random.choice(survivors)\n",
    "        parent2 = random.choice(survivors)\n",
    "\n",
    "        child = {\n",
    "            \"lr\": random.choice([parent1[\"lr\"], parent2[\"lr\"]]),\n",
    "            \"lambda\": random.choice([parent1[\"lambda\"], parent2[\"lambda\"]]),\n",
    "            \"epochs\": random.choice([parent1[\"epochs\"], parent2[\"epochs\"]]),\n",
    "        }\n",
    "\n",
    "        # mutation\n",
    "        if random.random() < MUTATION_RATE:\n",
    "            child[\"lr\"] *= random.uniform(0.8, 1.2)\n",
    "        if random.random() < MUTATION_RATE:\n",
    "            child[\"lambda\"] *= random.uniform(0.8, 1.2)\n",
    "\n",
    "        new_population.append(child)\n",
    "\n",
    "    population = new_population\n",
    "\n",
    "\n",
    "print(\"\\nBEST HYPERPARAMETERS FOUND:\")\n",
    "print(best_individual)\n",
    "print(\"Validation accuracy:\", best_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed8aa12",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e53a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL EVALUATION — TITANIC TEST SET\n",
      "============================================================\n",
      "\n",
      "Metrics:\n",
      "  Accuracy : 0.8101 (81.01%)\n",
      "  Precision: 0.7500\n",
      "  Recall   : 0.6774\n",
      "  F1-score : 0.7119\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               |  Died | Survived\n",
      "Actual Died    |  103  | 14\n",
      "Actual Survived|  20   | 42\n",
      "\n",
      "Probability Statistics:\n",
      "  Min : 0.0100\n",
      "  Max : 0.9612\n",
      "  Mean: 0.3520\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===============================\n",
    "# MODEL EVALUATION (FROM SCRATCH)\n",
    "# ===============================\n",
    "import matplotlib.pyplot as plt\n",
    "def predict_proba(X):\n",
    "    \"\"\"Return probability predictions for input X\"\"\"\n",
    "    return [\n",
    "        sigmoid(sum(weight[i] * row[i] for i in range(n_features)) + b)\n",
    "        for row in X\n",
    "    ]\n",
    "\n",
    "\n",
    "def predict(X, threshold=0.5):\n",
    "    return [1 if p >= threshold else 0 for p in predict_proba(X)]\n",
    "\n",
    "\n",
    "def evaluate_model(y_true, y_pred, y_proba=None, set_name=\"Dataset\"):\n",
    "\n",
    "\n",
    "    n = len(y_true)\n",
    "\n",
    "    # ---- Metrics helpers ----\n",
    "    def accuracy():\n",
    "        return sum(1 for i in range(n) if y_true[i] == y_pred[i]) / n\n",
    "\n",
    "    def precision():\n",
    "        tp = sum(1 for i in range(n) if y_true[i] == 1 and y_pred[i] == 1)\n",
    "        fp = sum(1 for i in range(n) if y_true[i] == 0 and y_pred[i] == 1)\n",
    "        return tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "\n",
    "    def recall():\n",
    "        tp = sum(1 for i in range(n) if y_true[i] == 1 and y_pred[i] == 1)\n",
    "        fn = sum(1 for i in range(n) if y_true[i] == 1 and y_pred[i] == 0)\n",
    "        return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    def f1():\n",
    "        p = precision()\n",
    "        r = recall()\n",
    "        return 2 * p * r / (p + r) if (p + r) > 0 else 0\n",
    "\n",
    "    def confusion_matrix():\n",
    "        tp = sum(1 for i in range(n) if y_true[i] == 1 and y_pred[i] == 1)\n",
    "        tn = sum(1 for i in range(n) if y_true[i] == 0 and y_pred[i] == 0)\n",
    "        fp = sum(1 for i in range(n) if y_true[i] == 0 and y_pred[i] == 1)\n",
    "        fn = sum(1 for i in range(n) if y_true[i] == 1 and y_pred[i] == 0)\n",
    "        return tp, tn, fp, fn\n",
    "\n",
    "    # ---- Compute ----\n",
    "    acc = accuracy()\n",
    "    prec = precision()\n",
    "    rec = recall()\n",
    "    f1s = f1()\n",
    "    tp, tn, fp, fn = confusion_matrix()\n",
    "\n",
    "    # ---- Display ----\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"MODEL EVALUATION — {set_name.upper()}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(\"\\nMetrics:\")\n",
    "    print(f\"  Accuracy : {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall   : {rec:.4f}\")\n",
    "    print(f\"  F1-score : {f1s:.4f}\")\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"                 Predicted\")\n",
    "    print(\"               |  Died | Survived\")\n",
    "    print(f\"Actual Died    |  {tn:<4} | {fp}\")\n",
    "    print(f\"Actual Survived|  {fn:<4} | {tp}\")\n",
    "\n",
    "    if y_proba is not None:\n",
    "        print(\"\\nProbability Statistics:\")\n",
    "        print(f\"  Min : {min(y_proba):.4f}\")\n",
    "        print(f\"  Max : {max(y_proba):.4f}\")\n",
    "        print(f\"  Mean: {sum(y_proba)/len(y_proba):.4f}\")\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1s,\n",
    "        \"TP\": tp,\n",
    "        \"TN\": tn,\n",
    "        \"FP\": fp,\n",
    "        \"FN\": fn\n",
    "    }\n",
    "\n",
    "y_proba = predict_proba(X_test)\n",
    "y_pred = predict(X_test, threshold=0.5)\n",
    "\n",
    "results = evaluate_model(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    y_proba=y_proba,\n",
    "    set_name=\"Titanic Test Set\"\n",
    ")\n",
    "\n",
    "def plot_sigmoid_with_model_outputs(X, y):\n",
    "    z_vals = [\n",
    "        sum(weight[j] * X[i][j] for j in range(len(weight))) + b\n",
    "        for i in range(len(X))\n",
    "    ]\n",
    "    probs = [sigmoid(z) for z in z_vals]\n",
    "\n",
    "    # Base sigmoid curve\n",
    "    z_curve = [i / 10 for i in range(-100, 101)]\n",
    "    s_curve = [sigmoid(z) for z in z_curve]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(z_curve, s_curve)\n",
    "\n",
    "    # Overlay points\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 1:\n",
    "            plt.scatter(z_vals[i], probs[i])\n",
    "        else:\n",
    "            plt.scatter(z_vals[i], probs[i])\n",
    "\n",
    "    plt.axhline(0.5)\n",
    "    plt.axvline(0.0)\n",
    "\n",
    "    plt.xlabel(\"z (weighted sum)\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.title(\"Sigmoid Curve with Model Predictions\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_sigmoid_with_model_outputs(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac373c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b99abe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f3a7ff6",
   "metadata": {},
   "source": [
    "# Prediksi Keselamatan Penumpang Titanic Menggunakan Logistic Regression\n",
    "\n",
    "## Anggota Kelompok\n",
    "\n",
    "* Hafizh Marfiansyah Putra - 103012300201\n",
    "* Azzahra Indah - 103012300238\n",
    "\n",
    "\n",
    "## Pendahuluan dan Paparan Data\n",
    "\n",
    "Tragedi tenggelamnya kapal **RMS Titanic** pada tahun 1912 merupakan salah satu peristiwa paling terkenal dalam sejarah pelayaran. Dari kejadian tersebut, tidak semua penumpang memiliki peluang yang sama untuk selamat. Faktor seperti kelas penumpang, jenis kelamin, usia, serta kondisi keluarga diduga memengaruhi tingkat keselamatan penumpang.\n",
    "\n",
    "Pada tugas besar ini, kami membangun sebuah **model Artificial Intelligence menggunakan algoritma Logistic Regression** untuk memprediksi apakah seorang penumpang Titanic **selamat (Survived)** atau **tidak selamat**, berdasarkan beberapa atribut penumpang yang tersedia dalam dataset.\n",
    "\n",
    "## Dataset dan Sumber Data\n",
    "\n",
    "Dataset yang digunakan adalah **Titanic Dataset**, yang berisi data penumpang kapal Titanic beserta status keselamatannya. Dataset ini banyak digunakan sebagai studi kasus dalam machine learning karena memiliki struktur data yang jelas dan relevan untuk klasifikasi biner.\n",
    "\n",
    "Variabel yang digunakan dalam penelitian ini adalah:\n",
    "\n",
    "* **Survived**: Status keselamatan penumpang (target)\n",
    "* **Pclass**: Kelas penumpang\n",
    "* **Sex**: Jenis kelamin\n",
    "* **Age**: Usia penumpang\n",
    "* **SibSp**: Jumlah saudara atau pasangan di kapal\n",
    "* **Parch**: Jumlah orang tua atau anak di kapal\n",
    "* **Fare**: Harga tiket\n",
    "* **Embarked**: Pelabuhan keberangkatan\n",
    "\n",
    "## Pre-processing Dataset\n",
    "\n",
    "Sebelum membangun model, dataset melalui beberapa tahapan pre-processing, antara lain:\n",
    "\n",
    "* Pemilihan fitur yang relevan sesuai variabel yang digunakan\n",
    "* Penanganan data kategorikal seperti **Sex** dan **Embarked**\n",
    "* Penanganan data kosong atau tidak valid\n",
    "* Penyesuaian format data agar dapat diproses oleh model Logistic Regression\n",
    "\n",
    "Tahapan ini bertujuan untuk meningkatkan kualitas data dan performa model yang dibangun.\n",
    "\n",
    "## Pembagian Data Training, Validasi, dan Testing\n",
    "\n",
    "Dataset dibagi menjadi tiga bagian untuk memastikan model dapat dilatih dan dievaluasi dengan baik:\n",
    "\n",
    "* **60% data** digunakan sebagai **training set** untuk melatih model\n",
    "* **20% data** digunakan sebagai **validation set** untuk mengevaluasi dan menyetel model\n",
    "* **20% data** digunakan sebagai **testing set** untuk mengukur performa akhir model\n",
    "\n",
    "Pembagian data dilakukan secara acak dengan menggunakan seed tertentu agar hasil eksperimen dapat direproduksi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a25fa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset split:\n",
      "Training   : 427\n",
      "Validation : 142\n",
      "Testing    : 143\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# ===============================\n",
    "# TRAIN / VALIDATION / TEST SPLIT (60 / 20 / 20)\n",
    "# ===============================\n",
    "random.seed(42)\n",
    "\n",
    "indices = list(range(len(X)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "n_total = len(indices)\n",
    "train_end = int(0.6 * n_total)\n",
    "val_end   = int(0.8 * n_total)\n",
    "\n",
    "train_idx = indices[:train_end]\n",
    "val_idx   = indices[train_end:val_end]\n",
    "test_idx  = indices[val_end:]\n",
    "\n",
    "X_train = [X[i] for i in train_idx]\n",
    "y_train = [y[i] for i in train_idx]\n",
    "\n",
    "X_val = [X[i] for i in val_idx]\n",
    "y_val = [y[i] for i in val_idx]\n",
    "\n",
    "X_test = [X[i] for i in test_idx]\n",
    "y_test = [y[i] for i in test_idx]\n",
    "\n",
    "print(\"\\nDataset split:\")\n",
    "print(\"Training   :\", len(X_train))\n",
    "print(\"Validation :\", len(X_val))\n",
    "print(\"Testing    :\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9ea6b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [2.281030444964871, 0.36065573770491804, 29.060117096018736, 0.4637002341920375, 0.4168618266978923, 32.8852355971897, 0.24824355971896955]\n",
      "Stds : [0.8014570259300761, 0.48019077101235447, 14.155581937394468, 0.9336129533561637, 0.8708102701367192, 54.02957558215128, 0.5159883598658702]\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# HELPER FUNCTIONS\n",
    "# ===============================\n",
    "\n",
    "def find_mean(dataset):\n",
    "    return sum(dataset) / len(dataset)\n",
    "\n",
    "def find_standard_deviation(dataset, mean):\n",
    "    return (sum((x - mean) ** 2 for x in dataset) / len(dataset)) ** 0.5\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# COMPUTE MEANS & STDS (TRAIN ONLY)\n",
    "# ===============================\n",
    "\n",
    "feature_means = []\n",
    "feature_stds = []\n",
    "\n",
    "for feature_idx in range(n_features):\n",
    "    column_values = [row[feature_idx] for row in X_train]\n",
    "\n",
    "    mean = find_mean(column_values)\n",
    "    std = find_standard_deviation(column_values, mean)\n",
    "\n",
    "    if std == 0:\n",
    "        std = 1.0\n",
    "\n",
    "    feature_means.append(mean)\n",
    "    feature_stds.append(std)\n",
    "\n",
    "print(\"Means:\", feature_means)\n",
    "print(\"Stds :\", feature_stds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b025a26b",
   "metadata": {},
   "source": [
    "## Metode dan Eksperimen\n",
    "\n",
    "### Metode yang Digunakan\n",
    "\n",
    "Pada penelitian ini, metode yang digunakan adalah **Logistic Regression**, yaitu salah satu algoritma klasifikasi biner yang memodelkan hubungan antara variabel input dan probabilitas suatu kelas. Logistic Regression digunakan untuk menghitung **probabilitas seorang penumpang Titanic selamat atau tidak selamat**, dengan memanfaatkan fungsi sigmoid sebagai fungsi aktivasi.\n",
    "\n",
    "Model dibangun dari awal tanpa menggunakan library machine learning eksternal. Proses pelatihan dilakukan menggunakan **gradient descent** dengan regularisasi L2 (ridge) untuk mengurangi risiko overfitting. Parameter model yang dipelajari meliputi bobot (weight) untuk setiap fitur dan sebuah bias.\n",
    "\n",
    "Fungsi sigmoid digunakan untuk mengubah hasil perhitungan linear menjadi nilai probabilitas antara 0 dan 1. Nilai probabilitas tersebut kemudian dikonversi menjadi kelas prediksi dengan threshold 0.5.\n",
    "\n",
    "### Pengukuran Kinerja Model\n",
    "\n",
    "Kinerja model dievaluasi menggunakan **metrik akurasi (accuracy)**. Akurasi mengukur seberapa besar proporsi prediksi yang benar dibandingkan dengan keseluruhan data.\n",
    "\n",
    "Evaluasi dilakukan pada tiga subset data:\n",
    "\n",
    "* **Training set** untuk melatih model\n",
    "* **Validation set** untuk memilih hyperparameter terbaik\n",
    "* **Testing set** untuk mengukur performa akhir model\n",
    "\n",
    "Penggunaan data validasi bertujuan agar proses pemilihan hyperparameter tidak bias terhadap data uji, sehingga hasil evaluasi lebih objektif.\n",
    "\n",
    "### Hyperparameter dan Hyperparameter Tuning\n",
    "\n",
    "Beberapa hyperparameter utama yang digunakan dalam model Logistic Regression adalah:\n",
    "\n",
    "* **Learning rate**, yang mengatur besar langkah pembaruan parameter\n",
    "* **Lambda**, sebagai parameter regularisasi untuk mengontrol kompleksitas model\n",
    "* **Jumlah epoch**, yang menentukan berapa kali proses pelatihan dilakukan terhadap seluruh data training\n",
    "\n",
    "Untuk memperoleh kombinasi hyperparameter yang optimal, digunakan metode **Genetic Algorithm**. Genetic Algorithm bekerja dengan meniru proses evolusi biologis, yaitu melalui tahapan inisialisasi populasi, evaluasi fitness, seleksi, crossover, dan mutasi.\n",
    "\n",
    "Setiap individu dalam populasi merepresentasikan satu kombinasi hyperparameter. Nilai **fitness** ditentukan berdasarkan akurasi model pada data validasi. Individu dengan performa terbaik akan dipertahankan dan dikombinasikan untuk menghasilkan generasi berikutnya.\n",
    "\n",
    "Proses ini dijalankan selama beberapa generasi hingga diperoleh kombinasi hyperparameter dengan performa validasi terbaik. Hyperparameter hasil Genetic Algorithm kemudian digunakan untuk melatih model akhir sebelum dilakukan pengujian pada data testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "313a00ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n",
      "\n",
      "Trained weights: [-0.5032533704344994, 1.8484911245378948, -0.027376731108499468, -0.24131936704292176, 0.05179414316065028, 0.0033397057643350936, -0.009711819698345928]\n",
      "Trained bias: 0.4766514618701213\n",
      "\n",
      "Test predictions (first 5):\n",
      "Sample 0: probability=0.5525, predicted=1, actual=1\n",
      "Sample 1: probability=0.1784, predicted=0, actual=0\n",
      "Sample 2: probability=0.6899, predicted=1, actual=1\n",
      "Sample 3: probability=0.2560, predicted=0, actual=0\n",
      "Sample 4: probability=0.1826, predicted=0, actual=1\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "# ===============================\n",
    "# HYPERPARAMETERS\n",
    "# ===============================\n",
    "learning_rate = 0.004294434790043332\n",
    "lambda_ = 0.007787368581333586\n",
    "epochs = 9001\n",
    "\n",
    "# ===============================\n",
    "# DATA SIZES\n",
    "# ===============================\n",
    "n_samples = len(X_train)\n",
    "n_features = len(X_train[0])\n",
    "\n",
    "# ===============================\n",
    "# INITIALIZE PARAMETERS\n",
    "# ===============================\n",
    "weight = [random.uniform(-0.01, 0.01) for _ in range(n_features)]\n",
    "b = 0.0\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# MODEL FUNCTIONS\n",
    "# ===============================\n",
    "def sigmoid(z):\n",
    "    if z >= 0:\n",
    "        return 1 / (1 + math.exp(-z))\n",
    "    else:\n",
    "        ez = math.exp(z)\n",
    "        return ez / (1 + ez)\n",
    "\n",
    "\n",
    "def find_weighted_sum_for_row(row):\n",
    "    return sum(weight[i] * row[i] for i in range(n_features)) + b\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# TRAINING\n",
    "# ===============================\n",
    "def train_logistic_regression(X_train, y_train, lr, lambda_, epochs):\n",
    "    n_samples = len(X_train)\n",
    "    n_features = len(X_train[0])\n",
    "\n",
    "    # initialize parameters\n",
    "    weight = [random.uniform(-0.01, 0.01) for _ in range(n_features)]\n",
    "    b = 0.0\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        preds = [\n",
    "            sigmoid(sum(weight[i] * X_train[j][i] for i in range(n_features)) + b)\n",
    "            for j in range(n_samples)\n",
    "        ]\n",
    "\n",
    "        # update weights\n",
    "        for i in range(n_features):\n",
    "            grad = sum((preds[j] - y_train[j]) * X_train[j][i] for j in range(n_samples)) / n_samples\n",
    "            grad += lambda_ * weight[i]\n",
    "            weight[i] -= lr * grad\n",
    "\n",
    "        # update bias\n",
    "        b_grad = sum(preds[j] - y_train[j] for j in range(n_samples)) / n_samples\n",
    "        b -= lr * b_grad\n",
    "\n",
    "    return weight, b\n",
    "\n",
    "\n",
    "def train_model(epochs):\n",
    "    global weight, b\n",
    "    weight, b = train_logistic_regression(X_train, y_train, learning_rate, lambda_, epochs)\n",
    "    print(f\"Training completed.\")\n",
    "\n",
    "def accuracy(X, y, weight, b):\n",
    "    correct = 0\n",
    "    for i in range(len(X)):\n",
    "        z = sum(weight[j] * X[i][j] for j in range(len(weight))) + b\n",
    "        pred = 1 if sigmoid(z) >= 0.5 else 0\n",
    "        if pred == y[i]:\n",
    "            correct += 1\n",
    "    return correct / len(X)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# TRAIN\n",
    "# ===============================\n",
    "train_model(epochs)\n",
    "\n",
    "print(\"\\nTrained weights:\", weight)\n",
    "print(\"Trained bias:\", b)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# TEST ON TEST SET\n",
    "# ===============================\n",
    "print(\"\\nTest predictions (first 5):\")\n",
    "for i in range(5):\n",
    "    p = sigmoid(find_weighted_sum_for_row(X_test[i]))\n",
    "    print(f\"Sample {i}: probability={p:.4f}, predicted={1 if p>=0.5 else 0}, actual={y_test[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7c12c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 0\n",
      "  {'lr': 0.016240907060331395, 'lambda': 0.005791060477767343, 'epochs': 8111} → val acc = 0.4366\n",
      "  {'lr': 0.029214039692208295, 'lambda': 0.009081181248963972, 'epochs': 9149} → val acc = 0.7324\n",
      "  {'lr': 0.020436067634314742, 'lambda': 0.007152996903444189, 'epochs': 4245} → val acc = 0.7394\n",
      "  {'lr': 0.03001279520124276, 'lambda': 0.00830741062146538, 'epochs': 6978} → val acc = 0.6831\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.030420169126025364, 'lambda': 0.0012193401000224781, 'epochs': 12272} → val acc = 0.7465\n",
      "  {'lr': 0.03934913197168996, 'lambda': 0.003478565615431406, 'epochs': 10018} → val acc = 0.7183\n",
      "  {'lr': 0.03341454569368044, 'lambda': 0.0006988777978312089, 'epochs': 13609} → val acc = 0.7394\n",
      "\n",
      "Generation 1\n",
      "  {'lr': 0.030420169126025364, 'lambda': 0.0012193401000224781, 'epochs': 12272} → val acc = 0.6549\n",
      "  {'lr': 0.020436067634314742, 'lambda': 0.007152996903444189, 'epochs': 4245} → val acc = 0.5915\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.03341454569368044, 'lambda': 0.0006988777978312089, 'epochs': 13609} → val acc = 0.6408\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7465\n",
      "  {'lr': 0.020436067634314742, 'lambda': 0.007152996903444189, 'epochs': 4245} → val acc = 0.7183\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.0012193401000224781, 'epochs': 14210} → val acc = 0.7183\n",
      "  {'lr': 0.020436067634314742, 'lambda': 0.00820723762466866, 'epochs': 14210} → val acc = 0.7394\n",
      "\n",
      "Generation 2\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7465\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7465\n",
      "  {'lr': 0.020436067634314742, 'lambda': 0.00820723762466866, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.020436067634314742, 'lambda': 0.007152996903444189, 'epochs': 4245} → val acc = 0.5915\n",
      "  {'lr': 0.020436067634314742, 'lambda': 0.00820723762466866, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.020436067634314742, 'lambda': 0.007152996903444189, 'epochs': 4245} → val acc = 0.6831\n",
      "  {'lr': 0.020436067634314742, 'lambda': 0.007152996903444189, 'epochs': 4245} → val acc = 0.7394\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7394\n",
      "\n",
      "Generation 3\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7465\n",
      "  {'lr': 0.020436067634314742, 'lambda': 0.00820723762466866, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.020436067634314742, 'lambda': 0.00820723762466866, 'epochs': 14210} → val acc = 0.5986\n",
      "  {'lr': 0.020436067634314742, 'lambda': 0.00820723762466866, 'epochs': 14210} → val acc = 0.5986\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7465\n",
      "  {'lr': 0.020436067634314742, 'lambda': 0.00820723762466866, 'epochs': 14210} → val acc = 0.7324\n",
      "  {'lr': 0.020436067634314742, 'lambda': 0.00820723762466866, 'epochs': 14210} → val acc = 0.7324\n",
      "\n",
      "Generation 4\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7465\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7465\n",
      "  {'lr': 0.020436067634314742, 'lambda': 0.00820723762466866, 'epochs': 14210} → val acc = 0.5986\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.008668654195603781, 'epochs': 14210} → val acc = 0.7324\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7394\n",
      "\n",
      "Generation 5\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7465\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7465\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7465\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.0063218266804007635, 'epochs': 14210} → val acc = 0.7535\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7465\n",
      "\n",
      "Generation 6\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.0063218266804007635, 'epochs': 14210} → val acc = 0.7535\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7465\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7465\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.0063218266804007635, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7465\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.005376565884236232, 'epochs': 14210} → val acc = 0.7676\n",
      "\n",
      "Generation 7\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.005376565884236232, 'epochs': 14210} → val acc = 0.7676\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.0063218266804007635, 'epochs': 14210} → val acc = 0.7535\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7465\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7465\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.005376565884236232, 'epochs': 14210} → val acc = 0.7676\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.007727084040662728, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.0063218266804007635, 'epochs': 14210} → val acc = 0.7535\n",
      "  {'lr': 0.006603114343911407, 'lambda': 0.006433822160292076, 'epochs': 14210} → val acc = 0.7254\n",
      "\n",
      "Generation 8\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.005376565884236232, 'epochs': 14210} → val acc = 0.7676\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.005376565884236232, 'epochs': 14210} → val acc = 0.7676\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.0063218266804007635, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.0063218266804007635, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.004725510645383068, 'epochs': 14210} → val acc = 0.7254\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.005376565884236232, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.005854621347096435, 'lambda': 0.0063218266804007635, 'epochs': 14210} → val acc = 0.7254\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.005989899422129262, 'epochs': 14210} → val acc = 0.7606\n",
      "\n",
      "Generation 9\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.005376565884236232, 'epochs': 14210} → val acc = 0.7676\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.005376565884236232, 'epochs': 14210} → val acc = 0.7676\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.005989899422129262, 'epochs': 14210} → val acc = 0.7606\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.0063218266804007635, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.005376565884236232, 'epochs': 14210} → val acc = 0.7394\n",
      "  {'lr': 0.005503623399608742, 'lambda': 0.005989899422129262, 'epochs': 14210} → val acc = 0.7887\n",
      "  {'lr': 0.006787486068590483, 'lambda': 0.005989899422129262, 'epochs': 14210} → val acc = 0.7254\n",
      "  {'lr': 0.0059931639668528505, 'lambda': 0.0063218266804007635, 'epochs': 14210} → val acc = 0.7535\n",
      "\n",
      "BEST HYPERPARAMETERS FOUND:\n",
      "{'lr': 0.005503623399608742, 'lambda': 0.005989899422129262, 'epochs': 14210}\n",
      "Validation accuracy: 0.7887323943661971\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# GENETIC ALGORITHM\n",
    "# ===============================\n",
    "\n",
    "POP_SIZE = 8\n",
    "GENERATIONS = 10\n",
    "MUTATION_RATE = 0.2\n",
    "\n",
    "\n",
    "def random_individual():\n",
    "    return {\n",
    "        \"lr\": random.uniform(0.001, 0.05),\n",
    "        \"lambda\": random.uniform(0.00001, 0.01),\n",
    "        \"epochs\": random.randint(3000, 15000)\n",
    "    }\n",
    "\n",
    "\n",
    "def fitness(individual):\n",
    "    weight, b = train_logistic_regression(X_train, y_train,individual[\"lr\"],individual[\"lambda\"],individual[\"epochs\"]\n",
    "    )\n",
    "    return accuracy(X_val, y_val, weight, b)\n",
    "\n",
    "\n",
    "# initialize population\n",
    "population = [random_individual() for _ in range(POP_SIZE)]\n",
    "\n",
    "best_individual = None\n",
    "best_score = 0\n",
    "\n",
    "for gen in range(GENERATIONS):\n",
    "    print(f\"\\nGeneration {gen}\")\n",
    "\n",
    "    scored = []\n",
    "    for ind in population:\n",
    "        score = fitness(ind)\n",
    "        scored.append((score, ind))\n",
    "        print(f\"  {ind} → val acc = {score:.4f}\")\n",
    "\n",
    "    scored.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "    if scored[0][0] > best_score:\n",
    "        best_score = scored[0][0]\n",
    "        best_individual = scored[0][1]\n",
    "\n",
    "    # selection (top 50%)\n",
    "    survivors = [ind for _, ind in scored[:POP_SIZE // 2]]\n",
    "\n",
    "    # crossover + mutation\n",
    "    new_population = survivors.copy()\n",
    "\n",
    "    while len(new_population) < POP_SIZE:\n",
    "        parent1 = random.choice(survivors)\n",
    "        parent2 = random.choice(survivors)\n",
    "\n",
    "        child = {\n",
    "            \"lr\": random.choice([parent1[\"lr\"], parent2[\"lr\"]]),\n",
    "            \"lambda\": random.choice([parent1[\"lambda\"], parent2[\"lambda\"]]),\n",
    "            \"epochs\": random.choice([parent1[\"epochs\"], parent2[\"epochs\"]]),\n",
    "        }\n",
    "\n",
    "        # mutation\n",
    "        if random.random() < MUTATION_RATE:\n",
    "            child[\"lr\"] *= random.uniform(0.8, 1.2)\n",
    "        if random.random() < MUTATION_RATE:\n",
    "            child[\"lambda\"] *= random.uniform(0.8, 1.2)\n",
    "\n",
    "        new_population.append(child)\n",
    "\n",
    "    population = new_population\n",
    "\n",
    "\n",
    "print(\"\\nBEST HYPERPARAMETERS FOUND:\")\n",
    "print(best_individual)\n",
    "print(\"Validation accuracy:\", best_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed8aa12",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9e53a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL EVALUATION — TITANIC TEST SET\n",
      "============================================================\n",
      "\n",
      "Metrics:\n",
      "  Accuracy : 0.7762 (77.62%)\n",
      "  Precision: 0.7674\n",
      "  Recall   : 0.6000\n",
      "  F1-score : 0.6735\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "               |  Died | Survived\n",
      "Actual Died    |  78   | 10\n",
      "Actual Survived|  22   | 33\n",
      "\n",
      "Probability Statistics:\n",
      "  Min : 0.0460\n",
      "  Max : 0.8499\n",
      "  Mean: 0.3263\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# MODEL EVALUATION (FROM SCRATCH)\n",
    "# ===============================\n",
    "\n",
    "def predict_proba(X):\n",
    "    \"\"\"Return probability predictions for input X\"\"\"\n",
    "    return [\n",
    "        sigmoid(sum(weight[i] * row[i] for i in range(n_features)) + b)\n",
    "        for row in X\n",
    "    ]\n",
    "\n",
    "\n",
    "def predict(X, threshold=0.5):\n",
    "    \"\"\"Return class predictions for input X\"\"\"\n",
    "    return [1 if p >= threshold else 0 for p in predict_proba(X)]\n",
    "\n",
    "\n",
    "def evaluate_model(y_true, y_pred, y_proba=None, set_name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Logistic Regression Evaluation (Binary Classification)\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(y_true)\n",
    "\n",
    "    # ---- Metrics helpers ----\n",
    "    def accuracy():\n",
    "        return sum(1 for i in range(n) if y_true[i] == y_pred[i]) / n\n",
    "\n",
    "    def precision():\n",
    "        tp = sum(1 for i in range(n) if y_true[i] == 1 and y_pred[i] == 1)\n",
    "        fp = sum(1 for i in range(n) if y_true[i] == 0 and y_pred[i] == 1)\n",
    "        return tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "\n",
    "    def recall():\n",
    "        tp = sum(1 for i in range(n) if y_true[i] == 1 and y_pred[i] == 1)\n",
    "        fn = sum(1 for i in range(n) if y_true[i] == 1 and y_pred[i] == 0)\n",
    "        return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    def f1():\n",
    "        p = precision()\n",
    "        r = recall()\n",
    "        return 2 * p * r / (p + r) if (p + r) > 0 else 0\n",
    "\n",
    "    def confusion_matrix():\n",
    "        tp = sum(1 for i in range(n) if y_true[i] == 1 and y_pred[i] == 1)\n",
    "        tn = sum(1 for i in range(n) if y_true[i] == 0 and y_pred[i] == 0)\n",
    "        fp = sum(1 for i in range(n) if y_true[i] == 0 and y_pred[i] == 1)\n",
    "        fn = sum(1 for i in range(n) if y_true[i] == 1 and y_pred[i] == 0)\n",
    "        return tp, tn, fp, fn\n",
    "\n",
    "    # ---- Compute ----\n",
    "    acc = accuracy()\n",
    "    prec = precision()\n",
    "    rec = recall()\n",
    "    f1s = f1()\n",
    "    tp, tn, fp, fn = confusion_matrix()\n",
    "\n",
    "    # ---- Display ----\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"MODEL EVALUATION — {set_name.upper()}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(\"\\nMetrics:\")\n",
    "    print(f\"  Accuracy : {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall   : {rec:.4f}\")\n",
    "    print(f\"  F1-score : {f1s:.4f}\")\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"                 Predicted\")\n",
    "    print(\"               |  Died | Survived\")\n",
    "    print(f\"Actual Died    |  {tn:<4} | {fp}\")\n",
    "    print(f\"Actual Survived|  {fn:<4} | {tp}\")\n",
    "\n",
    "    if y_proba is not None:\n",
    "        print(\"\\nProbability Statistics:\")\n",
    "        print(f\"  Min : {min(y_proba):.4f}\")\n",
    "        print(f\"  Max : {max(y_proba):.4f}\")\n",
    "        print(f\"  Mean: {sum(y_proba)/len(y_proba):.4f}\")\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1s,\n",
    "        \"TP\": tp,\n",
    "        \"TN\": tn,\n",
    "        \"FP\": fp,\n",
    "        \"FN\": fn\n",
    "    }\n",
    "\n",
    "y_proba = predict_proba(X_test)\n",
    "y_pred = predict(X_test, threshold=0.5)\n",
    "\n",
    "results = evaluate_model(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    y_proba=y_proba,\n",
    "    set_name=\"Titanic Test Set\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac373c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b99abe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
